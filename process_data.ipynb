{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_data(years_range=(2018, 2024)):\n",
    "    \"\"\"Load and combine F1 data from multiple years\"\"\"\n",
    "    data_dir = Path('./data')\n",
    "    dfs = []\n",
    "    \n",
    "    for year in range(years_range[0], years_range[1] + 1):\n",
    "        try:\n",
    "            filepath = data_dir / f'f1_data_{year}.csv'\n",
    "            if filepath.exists():\n",
    "                df = pd.read_csv(filepath)\n",
    "                dfs.append(df)\n",
    "                print(f\"Loaded data for {year}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {year}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No data files found\")\n",
    "        \n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nCombined dataset shape: {combined_df.shape}\")\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_prediction(df):\n",
    "    \"\"\"Process the combined data for position improvement\"\"\"\n",
    "   \n",
    "    # Print initial data shape\n",
    "    print(f\"\\nInitial data shape: {df.shape}\")\n",
    "   \n",
    "    # Create a clean copy of the data\n",
    "    df_clean = df.copy()\n",
    "   \n",
    "    # Remove rows with any null values\n",
    "    df_clean = df_clean.dropna()\n",
    "\n",
    "    # Process PitStopLaps to ensure it matches number of pit stops\n",
    "    def process_pit_stop_laps(num_pit_stops, pit_stop_laps):\n",
    "        # Convert inputs to appropriate type\n",
    "        num_pit_stops = int(num_pit_stops)\n",
    "        \n",
    "        # Convert pit_stop_laps to list if it's a string\n",
    "        if isinstance(pit_stop_laps, str):\n",
    "            pit_stop_laps = eval(pit_stop_laps)\n",
    "        \n",
    "        # Ensure the number of pit stop laps matches the number of pit stops\n",
    "        if len(pit_stop_laps) != num_pit_stops:\n",
    "            print(f\"Warning: Pit stops ({num_pit_stops}) and pit stop laps ({len(pit_stop_laps)}) do not match\")\n",
    "        \n",
    "        return pit_stop_laps[:num_pit_stops]\n",
    "\n",
    "    # Process TyreCompounds to ensure it matches number of pit stops + 1 (starting tyre)\n",
    "    def process_tyre_compounds_with_pit_stops(num_pit_stops, compounds_list):\n",
    "        # Convert inputs to appropriate type\n",
    "        num_pit_stops = int(num_pit_stops)\n",
    "        \n",
    "        # Convert compounds to list if it's a string\n",
    "        if isinstance(compounds_list, str):\n",
    "            compounds_list = eval(compounds_list)\n",
    "        \n",
    "        # Remove 'UNKNOWN' compounds\n",
    "        cleaned_compounds = [comp for comp in compounds_list if comp != 'UNKNOWN']\n",
    "        \n",
    "        # Ensure the number of compounds is number of pit stops + 1 (starting tyre)\n",
    "        if len(cleaned_compounds) != num_pit_stops + 1:\n",
    "            print(f\"Warning: Pit stops + 1 ({num_pit_stops + 1}) and tyre compounds ({len(cleaned_compounds)}) do not match\")\n",
    "        \n",
    "        return cleaned_compounds[:num_pit_stops + 1]\n",
    "\n",
    "    # Apply processing to PitStopLaps and TyreCompounds\n",
    "    df_clean['PitStopLaps'] = df_clean.apply(\n",
    "        lambda row: process_pit_stop_laps(row['NumPitStops'], row['PitStopLaps']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df_clean['TyreCompounds'] = df_clean.apply(\n",
    "        lambda row: process_tyre_compounds_with_pit_stops(row['NumPitStops'], row['TyreCompounds']), \n",
    "        axis=1\n",
    "    )\n",
    "   \n",
    "    # Convert Q1Time to float if it's not already\n",
    "    df_clean['Q1Time'] = df_clean['Q1Time'].astype(float)\n",
    "   \n",
    "    # Convert Laps to integer\n",
    "    df_clean['Laps'] = df_clean['Laps'].astype(int)\n",
    "   \n",
    "    # Create mappings for categorical variables\n",
    "    mappings = {}\n",
    "   \n",
    "    # Handle categorical variables including Season\n",
    "    categorical_columns = ['Season', 'Circuit', 'Team', 'Driver']\n",
    "    for col in categorical_columns:\n",
    "        # Filter out any None or unknown values\n",
    "        valid_values = df_clean[col].dropna().unique()\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        filtered_labels = [label for label in valid_values]\n",
    "        le.fit(filtered_labels)\n",
    "        \n",
    "        df_clean.loc[:, f'{col}_encoded'] = le.transform(df_clean[col])\n",
    "        \n",
    "        # Convert numpy types to native Python types for JSON serialization\n",
    "        mapping = {str(k): int(v) for k, v in zip(le.classes_, le.transform(le.classes_))}\n",
    "        mappings[col] = mapping\n",
    "    \n",
    "    # Create tyre compound mapping\n",
    "    def create_tyre_mapping(all_compounds):\n",
    "        # Flatten and get unique tyre compounds\n",
    "        unique_compounds = sorted(set([compound for sublist in all_compounds for compound in sublist]))\n",
    "        return {compound: idx for idx, compound in enumerate(unique_compounds)}\n",
    "    \n",
    "    tyre_mapping = create_tyre_mapping(df_clean['TyreCompounds'])\n",
    "    mappings['TyreCompounds'] = tyre_mapping\n",
    "    \n",
    "    # Convert TyreCompounds to encoded lists\n",
    "    def encode_tyre_compounds(compounds):\n",
    "        return [tyre_mapping[compound] for compound in compounds]\n",
    "    \n",
    "    df_clean.loc[:, 'TyreCompounds_encoded'] = df_clean['TyreCompounds'].apply(encode_tyre_compounds)\n",
    "    \n",
    "    # Select features for prediction\n",
    "    feature_columns = [\n",
    "        'Season_encoded', 'Round', 'Circuit_encoded',\n",
    "        'Laps', 'NumParticipants', 'AirTemp',\n",
    "        'Humidity', 'Pressure','TrackTemp',\n",
    "        'WindDirection', 'WindSpeed', 'Team_encoded',\n",
    "        'Driver_encoded', 'Q1Time', 'GridPosition',\n",
    "        'NumPitStops', 'PitStopLaps', 'TyreCompounds_encoded'  # Encoded tyre compounds\n",
    "    ]\n",
    "\n",
    "    # Split features into numerical and categorical\n",
    "    numerical_features = [\n",
    "        'Round', 'GridPosition',\n",
    "        'NumParticipants', 'NumPitStops',\n",
    "        'AirTemp', 'Humidity', 'Pressure',\n",
    "        'TrackTemp', 'WindDirection', 'WindSpeed', 'Q1Time', 'Laps'\n",
    "    ]\n",
    "   \n",
    "    categorical_features = [\n",
    "        'Season_encoded', 'Circuit_encoded', 'Team_encoded', 'Driver_encoded',\n",
    "        'TyreCompounds_encoded', 'PitStopLaps'  # Encoded lists as categorical features\n",
    "    ]\n",
    "   \n",
    "    # Create target variables\n",
    "    target_columns = ['ClassificationResult']\n",
    "    df_clean['ClassificationResult'] = -1 * df_clean['ClassificationResult']\n",
    "    \n",
    "    # Create the feature matrix and target variables\n",
    "    X = df_clean[feature_columns].copy()\n",
    "    y = df_clean[target_columns].copy()\n",
    "   \n",
    "    return X, y, numerical_features, categorical_features, target_columns, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mappings(mappings, year_range):\n",
    "    \"\"\"Save the feature mappings to JSON files\"\"\"\n",
    "    # Create mappings directory\n",
    "    mappings_dir = Path('./data/mappings')\n",
    "    mappings_dir.mkdir(parents=True, exist_ok=True)\n",
    "   \n",
    "    # Save each mapping to a separate file\n",
    "    for feature, mapping in mappings.items():\n",
    "        filename = mappings_dir / f'{feature}_mapping_{year_range[0]}_{year_range[1]}.json'\n",
    "        print(f\"Saving mapping for {feature} with {len(mapping)} items\")\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(mapping, f, indent=4, sort_keys=True)\n",
    "        print(f\"Saved mapping for {feature} to {filename}\")\n",
    "\n",
    "def analyze_data(X, y, numerical_features, categorical_features, target_columns):\n",
    "    \"\"\"Analyze the processed data\"\"\"\n",
    "    print(\"\\nFeature Statistics:\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"Number of numerical features: {len(numerical_features)}\")\n",
    "    print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "   \n",
    "    print(\"\\nNumerical Features:\")\n",
    "    for col in numerical_features:\n",
    "        print(f\"- {col}\")\n",
    "        print(f\"  Mean: {X[col].mean():.2f}\")\n",
    "        print(f\"  Std: {X[col].std():.2f}\")\n",
    "        print(f\"  Min: {X[col].min():.2f}\")\n",
    "        print(f\"  Max: {X[col].max():.2f}\")\n",
    "   \n",
    "    print(\"\\nCategorical Features:\")\n",
    "    for col in categorical_features:\n",
    "        print(f\"- {col}\")\n",
    "        if col in ['TyreCompounds_encoded', 'PitStopLaps']:\n",
    "            # Special handling for list-type features\n",
    "            print(f\"  Unique compound/lap combinations: {len(set(tuple(x) for x in X[col]))}\")\n",
    "            print(f\"  Average list length: {X[col].apply(len).mean():.2f}\")\n",
    "        else:\n",
    "            print(f\"  Unique values: {X[col].nunique()}\")\n",
    "   \n",
    "    print(\"\\nTarget Statistics:\")\n",
    "    print(\"-----------------\")\n",
    "    for col in target_columns:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"Mean: {y[col].mean():.2f}\")\n",
    "        print(f\"Std: {y[col].std():.2f}\")\n",
    "        print(f\"Min: {y[col].min():.2f}\")\n",
    "        print(f\"Max: {y[col].max():.2f}\")\n",
    "   \n",
    "    # Save analysis\n",
    "    with open(Path('./data/prediction_data_analysis.txt'), 'w') as f:\n",
    "        f.write(\"F1 Race Prediction Data Analysis\\n\")\n",
    "        f.write(\"===============================\\n\\n\")\n",
    "        f.write(f\"Total samples: {len(X)}\\n\")\n",
    "        f.write(f\"Numerical features: {len(numerical_features)}\\n\")\n",
    "        f.write(f\"Categorical features: {len(categorical_features)}\\n\\n\")\n",
    "       \n",
    "        f.write(\"Numerical Features:\\n\")\n",
    "        for col in numerical_features:\n",
    "            f.write(f\"- {col}\\n\")\n",
    "            f.write(f\"  Mean: {X[col].mean():.2f}\\n\")\n",
    "            f.write(f\"  Std: {X[col].std():.2f}\\n\")\n",
    "            f.write(f\"  Min: {X[col].min():.2f}\\n\")\n",
    "            f.write(f\"  Max: {X[col].max():.2f}\\n\")\n",
    "       \n",
    "        f.write(\"\\nCategorical Features:\\n\")\n",
    "        for col in categorical_features:\n",
    "            f.write(f\"- {col}\\n\")\n",
    "            if col in ['TyreCompounds_encoded', 'PitStopLaps']:\n",
    "                # Special handling for list-type features\n",
    "                f.write(f\"  Unique compound/lap combinations: {len(set(tuple(x) for x in X[col]))}\\n\")\n",
    "                f.write(f\"  Average list length: {X[col].apply(len).mean():.2f}\\n\")\n",
    "            else:\n",
    "                f.write(f\"  Unique values: {X[col].nunique()}\\n\")\n",
    "       \n",
    "        f.write(\"\\nTarget Variables:\\n\")\n",
    "        for col in target_columns:\n",
    "            f.write(f\"{col}:\\n\")\n",
    "            f.write(f\"Mean: {y[col].mean():.2f}\\n\")\n",
    "            f.write(f\"Std: {y[col].std():.2f}\\n\")\n",
    "            f.write(f\"Min: {y[col].min():.2f}\\n\")\n",
    "            f.write(f\"Max: {y[col].max():.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and combining data...\n",
      "Loaded data for 2018\n",
      "Loaded data for 2019\n",
      "Loaded data for 2020\n",
      "Loaded data for 2021\n",
      "Loaded data for 2022\n",
      "Loaded data for 2023\n",
      "Loaded data for 2024\n",
      "\n",
      "Combined dataset shape: (2424, 22)\n",
      "\n",
      "Processing data for prediction...\n",
      "\n",
      "Initial data shape: (2424, 22)\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (5) and tyre compounds (4) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (1) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (1) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (1) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (1) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (1) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (4) and tyre compounds (3) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (3) and tyre compounds (2) do not match\n",
      "Warning: Pit stops + 1 (2) and tyre compounds (3) do not match\n",
      "\n",
      "Saving feature mappings...\n",
      "Saving mapping for Season with 7 items\n",
      "Saved mapping for Season to data\\mappings\\Season_mapping_2018_2024.json\n",
      "Saving mapping for Circuit with 34 items\n",
      "Saved mapping for Circuit to data\\mappings\\Circuit_mapping_2018_2024.json\n",
      "Saving mapping for Team with 18 items\n",
      "Saved mapping for Team to data\\mappings\\Team_mapping_2018_2024.json\n",
      "Saving mapping for Driver with 40 items\n",
      "Saved mapping for Driver to data\\mappings\\Driver_mapping_2018_2024.json\n",
      "Saving mapping for TyreCompounds with 8 items\n",
      "Saved mapping for TyreCompounds to data\\mappings\\TyreCompounds_mapping_2018_2024.json\n",
      "\n",
      "Analyzing processed data...\n",
      "\n",
      "Feature Statistics:\n",
      "------------------\n",
      "Number of numerical features: 12\n",
      "Number of categorical features: 6\n",
      "\n",
      "Numerical Features:\n",
      "- Round\n",
      "  Mean: 11.24\n",
      "  Std: 6.33\n",
      "  Min: 1.00\n",
      "  Max: 24.00\n",
      "- GridPosition\n",
      "  Mean: 9.95\n",
      "  Std: 5.74\n",
      "  Min: 0.00\n",
      "  Max: 20.00\n",
      "- NumParticipants\n",
      "  Mean: 19.99\n",
      "  Std: 0.08\n",
      "  Min: 19.00\n",
      "  Max: 20.00\n",
      "- NumPitStops\n",
      "  Mean: 1.68\n",
      "  Std: 0.78\n",
      "  Min: 1.00\n",
      "  Max: 6.00\n",
      "- AirTemp\n",
      "  Mean: 23.55\n",
      "  Std: 4.94\n",
      "  Min: 9.00\n",
      "  Max: 36.30\n",
      "- Humidity\n",
      "  Mean: 52.70\n",
      "  Std: 15.55\n",
      "  Min: 8.00\n",
      "  Max: 95.50\n",
      "- Pressure\n",
      "  Mean: 986.50\n",
      "  Std: 48.76\n",
      "  Min: 781.20\n",
      "  Max: 1023.50\n",
      "- TrackTemp\n",
      "  Mean: 36.68\n",
      "  Std: 9.07\n",
      "  Min: 14.50\n",
      "  Max: 57.00\n",
      "- WindDirection\n",
      "  Mean: 196.29\n",
      "  Std: 107.30\n",
      "  Min: 0.00\n",
      "  Max: 358.00\n",
      "- WindSpeed\n",
      "  Mean: 1.68\n",
      "  Std: 1.12\n",
      "  Min: 0.00\n",
      "  Max: 6.00\n",
      "- Q1Time\n",
      "  Mean: 85.43\n",
      "  Std: 12.42\n",
      "  Min: 54.16\n",
      "  Max: 141.61\n",
      "- Laps\n",
      "  Mean: 60.45\n",
      "  Std: 8.78\n",
      "  Min: 44.00\n",
      "  Max: 87.00\n",
      "\n",
      "Categorical Features:\n",
      "- Season_encoded\n",
      "  Unique values: 7\n",
      "- Circuit_encoded\n",
      "  Unique values: 34\n",
      "- Team_encoded\n",
      "  Unique values: 18\n",
      "- Driver_encoded\n",
      "  Unique values: 40\n",
      "- TyreCompounds_encoded\n",
      "  Unique compound/lap combinations: 208\n",
      "  Average list length: 2.66\n",
      "- PitStopLaps\n",
      "  Unique compound/lap combinations: 869\n",
      "  Average list length: 1.68\n",
      "\n",
      "Target Statistics:\n",
      "-----------------\n",
      "ClassificationResult:\n",
      "Mean: 0.01\n",
      "Std: 4.90\n",
      "Min: -20.00\n",
      "Max: 16.00\n",
      "\n",
      "Saving processed data...\n",
      "\n",
      "Data processing complete!\n"
     ]
    }
   ],
   "source": [
    "year_range = (2018, 2024)\n",
    "\n",
    "# Load and combine data\n",
    "print(\"Loading and combining data...\")\n",
    "combined_df = load_and_combine_data(year_range)\n",
    "\n",
    "# Process data for prediction\n",
    "print(\"\\nProcessing data for prediction...\")\n",
    "X, y, numerical_features, categorical_features, target_columns, mappings = process_for_prediction(combined_df)\n",
    "\n",
    "# Save feature mappings\n",
    "print(\"\\nSaving feature mappings...\")\n",
    "save_mappings(mappings, year_range)\n",
    "\n",
    "# Analyze processed data\n",
    "print(\"\\nAnalyzing processed data...\")\n",
    "analyze_data(X, y, numerical_features, categorical_features, target_columns)\n",
    "\n",
    "# Save processed data\n",
    "print(\"\\nSaving processed data...\")\n",
    "data_dir = Path('./data')\n",
    "X.to_csv(data_dir / 'processed_features.csv', index=False)\n",
    "y.to_csv(data_dir / 'processed_targets.csv', index=False)\n",
    "\n",
    "# Save feature lists for later use\n",
    "feature_info = {\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'target_columns': target_columns\n",
    "}\n",
    "import json\n",
    "with open(data_dir / 'feature_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=4)\n",
    "\n",
    "print(\"\\nData processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
